include "actors"
include "mysql"
include "markets"

akka {
  log-config-on-start = off
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  logger-startup-timeout = 30s
  stdout-loglevel = "DEBUG"
  log-dead-letters = 0
  log-dead-letters-during-shutdown = off
  default-receive-loglevel ="DEBUG"

  actor {
    provider = "cluster"

    serializers {
      java = "akka.serialization.JavaSerializer"
      proto = "akka.remote.serialization.ProtobufSerializer"
    }

    serialization-bindings {
      "com.google.protobuf.GeneratedMessageV3" = proto
      "scalapb.GeneratedMessage" = proto
    }

    allow-java-serialization = off
    enable-additional-serialization-bindings = true
    debug {
      receive = on
      autoreceive = on
      lifecycle = on
      unhandled = on
    }
  }
  remote {
    log-remote-lifecycle-events = on
    log-sent-messages = on
    log-received-messages = on
    log-frame-size-exceeding = 2000b

//    artery {
//      enabled = on
//      transport = aeron-udp
//      canonical.port = 0
//      canonical.hostname = 127.0.0.1
//    }
    netty.tcp {
      hostname = "127.0.0.1"
      port = 9090
    }
  }
  cluster {
    seed-nodes = [
      "akka.tcp://Lightcone@127.0.0.1:9090"]

    # auto downing is NOT safe for production deployments.
    # you may want to use it during development, read more about it in the docs.
    auto-down-unreachable-after = 10s

  }
}
akka.cluster.jmx.multi-mbeans-in-same-jvm = on
# Enable metrics extension in akka-cluster-metrics.
akka.extensions=[
  "akka.cluster.metrics.ClusterMetricsExtension",
  "akka.cluster.pubsub.DistributedPubSub"
]

ring-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 1
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 2.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 2
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 10
}

ethereum {
  ssl = false
  host = "127.0.0.1"
  port = 8545 // 8080为ethcube端口,8545为geth默认端口
  queueSize = 20
}

behaviors {
  future-wait-timeout = 2 // second
}


// todo: delete after test
// 本地测试时数据
// cancel order: 43163
// submit ring: 43206
// cutoff all: 43168
// cutoff pair: 43170
extractor {
  start-block = 43163 // 程序首次启动时要避免块号踩在分叉链上,最好是低于当前块一定高度
}

redis {
  servers = [{
    host = "127.0.0.1"
    port = 6379
    password = "111111"
  }]
}

socketio {
  port = 9077
  pool = 10
}

cmc-config {
  header = "X-CMC_PRO_API_KEY"
  api_key = "b2e14d15-a592-49a4-8d0d-18bcba5419e7"
  prefix_url = "pro-api.coinmarketcap.com"
  limitSize = 5000
  convertCurrency = "USD,CNY"
  //pageCount = 1 //分页页码控制
}

my_token {
  app_id = "83ga_-yxA_yKiFyL"
  app_secret = "glQVQRP8ro-QRN59CpXj12TzwgJ1rM8w"
  host_url = "openapi.mytokenapi.com"
  limit_size = 180
  period = "1d"
  trend_anchor = "usd"
}
// !!! 注意，ethereumJ暂时不支持fallback数据结构
//address {
//  protocol = "0x781870080C8C24a2FD6882296c49c837b06A65E6"
//  delegate = "0xC533531f4f291F036513f7Abb41bfcCc62475486"
//}